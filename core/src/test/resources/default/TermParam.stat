80 columns                                                                     |
<<< unindent by 2 in blocks, #186
scrut.branchSwitch(scrut.value,
                   casevals = normalcases.map { case (v, _) => v },
                   casefs = normalcases.map {
                       case (_, body) => genExpr(body, _: Focus)
                     })
>>>
scrut.branchSwitch(scrut.value,
                   casevals = normalcases.map { case (v, _) => v },
                   casefs = normalcases.map {
                     case (_, body) => genExpr(body, _: Focus)
                   })
<<< SKIP indent negative weird, lila
+                negotiate(
+                    html = fuccess(redirectPov(pov)),
+                    api = apiVersion =>
+                        Env.api.roundApi.player(pov, apiVersion) map { data =>
+                        Created(data) as JSON
+                    }
+                )
>>>
x
<<< break type
{
def train(points: RDD[LabeledPoint]): CategoricalNaiveBayesModel = {
    val labelCountFeatureLikelihoods = points.map { p =>
      (p.label, p.features)
    }.combineByKey[(Long, Array[Map[String, Long]])](
          createCombiner = (features: Array[String]) => {
            val featureCounts = features.map { feature =>
              Map[String, Long]().withDefaultValue(0L).updated(feature, 1L)
            }

            (1L, featureCounts)
          },
          mergeValue = (c: (Long,
            Array[Map[String, Long]]), features: Array[String]) => {
            (c._1 + 1L,
             c._2
               .zip(features)
               .map {
                 case (m, feature) =>
                   m.updated(feature, m(feature) + 1L)
               })
          }
          mergeCombiners = (c1: (Long, Array[Map[String, Long]]), c2: (Long,
            Array[Map[String, Long]])) => {
            val labelCount1 = c1._1
            val labelCount2 = c2._1
            val featureCounts1 = c1._2
            val featureCounts2 = c2._2

            (labelCount1 + labelCount2,
             featureCounts1
               .zip(featureCounts2)
               .map {
                 case (m1, m2) =>
                   m2 ++ m2.map { case (k, v) => k -> (v + m2(k)) }
               })
          }
      )
      .collect()
      .toMap
      }}
>>>
{
  def train(points: RDD[LabeledPoint]): CategoricalNaiveBayesModel = {
    val labelCountFeatureLikelihoods = points.map { p =>
      (p.label, p.features)
    }.combineByKey[(Long, Array[Map[String, Long]])](
          createCombiner = (features: Array[String]) => {
            val featureCounts = features.map { feature =>
              Map[String, Long]().withDefaultValue(0L).updated(feature, 1L)
            }

            (1L, featureCounts)
          },
          mergeValue = (c: (Long, Array[Map[String, Long]]),
                        features: Array[String]) => {
            (c._1 + 1L,
             c._2
               .zip(features)
               .map {
                 case (m, feature) =>
                   m.updated(feature, m(feature) + 1L)
               })
          } mergeCombiners = (c1: (Long, Array[Map[String, Long]]),
                              c2: (Long, Array[Map[String, Long]])) => {
            val labelCount1 = c1._1
            val labelCount2 = c2._1
            val featureCounts1 = c1._2
            val featureCounts2 = c2._2

            (labelCount1 + labelCount2,
             featureCounts1
               .zip(featureCounts2)
               .map {
                 case (m1, m2) =>
                   m2 ++ m2.map { case (k, v) => k -> (v + m2(k)) }
               })
          }
      )
      .collect()
      .toMap
  }
}
